{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0a71bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d302a",
   "metadata": {},
   "source": [
    "### Understanding Stores in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28880508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Things to Do in Montreal \\nMontréal is a vibrant city with a rich cultural heritage and an array of activities to suit every \\ninterest. \\nOld Montreal  \\nDebute  your exploration in the historic Old Montreal, where cobblestone streets and 17th-\\ncentury architecture transport you back in time. Visit the stunning Notre-Dame Basilica, \\nrenowned for its intricate interior and dramatic light shows. \\nMontreal Museum of Fine Arts  \\nFor a taste of the local arts scene, head to the Montreal Museum of Fine Arts, home to an \\nimpressive collection of Canadian and international works. \\nMont Royal  \\nIf you're an outdoor enthusiast, Mont Royal o Ưers scenic hiking trails and panoramic views \\nof the city. In the summer, the park becomes a hub for picnics and outdoor events, \\nincluding the popular Tam-Tams festival, where locals gather to enjoy music and dance. \\nMile End District   \\nFor a modern twist, the Mile End district is a must-visit. Known for its bohemian vibe, this \\narea is packed with indie boutiques, art galleries, and eclectic cafes. Don’t miss the vibrant \\nstreet art that adorns many of the buildings here. \\nMontreal’s Underground City   \\nIf you're visiting in the winter, Montreal’s Underground City is a unique experience, \\nproviding over 30 kilometers of pedestrian pathways that connect shops, hotels, and metro \\nstations, all sheltered from the cold. \\nFestivals   \\nAdditionally, the city is famous for its festivals, such as the Montreal International Jazz \\nFestival and Just for Laughs, which attract visitors from around the globe.\", metadata={'source': 'data\\\\montreal.pdf', 'page': 0}),\n",
       " Document(page_content='Dining in Montreal \\nMontreal’s culinary scene is just as diverse and exciting as its activities. \\nSchwartz’s Deli  \\nStart your gastronomic journey with a visit to Schwartz’s Deli, an iconic establishment \\nknown for its mouth-watering smoked meat sandwiches. \\nLa Banquise  \\nFor a true taste of Montreal, try poutine – a delectable dish of fries topped with cheese \\ncurds and gravy – available at La Banquise, a local favorite that o Ưers numerous variations \\nof this classic comfort food. \\nToqué!  \\nFor ﬁne dining, Toqué! is a standout choice, o Ưering an innovative menu that highlights \\nseasonal ingredients and Quebecois ﬂavors. \\nJoe Beef  \\nFoodies will also appreciate Joe Beef, a beloved bistro that combines French culinary \\ntechniques with hearty, local ingredients. \\nFairmount Bagel and St-Viateur Bagel  \\nIf you’re in the mood for something sweet, a stop at Fairmount Bagel or St-Viateur Bagel is \\nessential. These bagel shops have been serving freshly baked, wood-ﬁred bagels for \\ndecades and are a staple of Montreal’s food culture. \\nCandide and Damas  \\nIn the mood for something more exotic? Try Candide, which serves contemporary dishes \\nwith a focus on local and sustainable ingredients, or Damas, a high-end Syrian restaurant \\nknown for its exquisite Middle Eastern cuisine. \\nWith its diverse array of dining options, Montreal truly o Ưers something for every palate.', metadata={'source': 'data\\\\montreal.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = r\"data\\montreal.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "# by default, we will split by pages with no text_splitter\n",
    "documents = loader.load_and_split(text_splitter=None)\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d7f0f",
   "metadata": {},
   "source": [
    "### Unsing the InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4e299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiVectorRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001F73911E050>, docstore=<langchain_core.stores.InMemoryBaseStore object at 0x000001F73AB4A010>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from database import COLLECTION_NAME\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    docstore=store, \n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e5a7f",
   "metadata": {},
   "source": [
    "### Unsing the PostgresByteStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833c1001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiVectorRetriever(vectorstore=<langchain_postgres.vectorstores.PGVector object at 0x000001F73AFD5550>, docstore=<utils.store.PostgresByteStore object at 0x000001F70EE10A10>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_postgres import PGVector\n",
    "from database import COLLECTION_NAME, CONNECTION_STRING\n",
    "from utils.store import PostgresByteStore\n",
    "from langchain_postgres import PostgresSaver, PickleCheckpointSerializer\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection=CONNECTION_STRING,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "store = PostgresByteStore(CONNECTION_STRING, COLLECTION_NAME)\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    docstore=store, \n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in documents]\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "all_sub_docs = []\n",
    "for i, doc in enumerate(documents):\n",
    "    doc_id = doc_ids[i]\n",
    "    sub_docs = child_text_splitter.split_documents([doc])\n",
    "    for sub_doc in sub_docs:\n",
    "        sub_doc.metadata[id_key] = doc_id\n",
    "    all_sub_docs.extend(sub_docs)\n",
    "    \n",
    "all_sub_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(all_sub_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ff698",
   "metadata": {},
   "source": [
    "### Testing the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19051b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "retriever.vectorstore.similarity_search(\"What are some unique seasonal events in Montreal that a visitor should not miss?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8436abc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "retriever.invoke(\"What are some unique seasonal events in Montreal that a visitor should not miss?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b2e37",
   "metadata": {},
   "source": [
    "### Creating Summaries for Each Parent Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0407a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing text. \\\n",
    "Directly summarize the following text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Initialize the Language Model (LLM)\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "# Define the summary chain\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_chunk = [i.page_content for i in documents]\n",
    "text_summaries = summarize_chain.batch(parent_chunk, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830970cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "summary_docs = []\n",
    "for i, (summary, doc_id) in enumerate(zip(text_summaries, doc_ids)):\n",
    "    # Define your new metadata here\n",
    "    new_metadata = {\"page\": i, \"doc_id\": doc_id}\n",
    "\n",
    "    # Create a new Document instance for each summary\n",
    "    doc = Document(page_content=str(summary))\n",
    "\n",
    "    # Replace the metadata\n",
    "    doc.metadata = new_metadata\n",
    "\n",
    "    # Add the Document to the list\n",
    "    summary_docs.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf4b08",
   "metadata": {},
   "source": [
    "### Generating Hypothetical Questions for Each Parent Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec26a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",\n",
    "        \"description\": \"Generate hypothetical questions\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"questions\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e853c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "question_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # Only asking for 5 hypothetical questions, but this could be adjusted\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"\"\"Generate a list of exactly 5 hypothetical questions that the below document could be used to answer:\\n\\n{doc}\n",
    "        seperate each question with a comma (,)\n",
    "        \"\"\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4o\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_questions = question_chain.batch(documents, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "hypothetical_docs = []\n",
    "for question_list, doc_id in zip(hypothetical_questions, doc_ids):\n",
    "    for question in question_list:\n",
    "        # Define your new metadata here\n",
    "        new_metadata = {\"doc_id\": doc_id}\n",
    "\n",
    "        # Create a new Document instance for each question\n",
    "        # The question itself is the page_content\n",
    "        doc = Document(page_content=question, metadata=new_metadata)\n",
    "\n",
    "        # Add the Document to the list\n",
    "        hypothetical_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524590ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12247d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(hypothetical_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.similarity_search(\"What dining options are available in Montreal for those interested in Middle Eastern cuisine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"What dining options are available in Montreal for those interested in Middle Eastern cuisine?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdbcd4",
   "metadata": {},
   "source": [
    "### Creating an LCEL Chain and Testing the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Prompt template\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What dining options are available in Montreal for those interested in Middle Eastern cuisine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"Where can I find the best smoked meat sandwiches in Montreal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"Where can I find the best food in Montreal?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
